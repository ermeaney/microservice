---

- name: add analytic user
  command: sudo useradd analytics -u 9000 -d /home/analytics  -m  creates=/home/analytics

- name: Creates directory /data/dfs dir for hdfs
  file: path={{ item.path }} state=directory owner=analytics
  with_items:
    - { path: '/data/dfs' }
  when: "'hdfs_nn' in group_names or 'hdfs_dn' in group_names or 'hdfs_cli' in group_names"

- name: Creates spark directory
  file: path={{ item.path }} state=directory owner=analytics
  with_items:
    - { path: '/etc/spark' }
    - { path: '/opt/spark/recovery' }
    - { path: '/opt/spark/data' }
    - { path: '/opt/spark/work' }
  when: "'spark_master' in group_names or 'spark_slave' in group_names"

- name: Copy spark files
  template: src="{{ item.src }}" dest="/etc/spark/{{ item.dest }}" mode="{{ item.mode }}"
  with_items:
    - { src: 'spark.metrics.properties.j2', dest: 'metrics.properties', mode: '755' }
    - { src: 'spark.spark-defaults.conf.j2', dest: 'spark-defaults.conf', mode: '755' }
    - { src: 'spark.spark-env.sh.j2', dest: 'spark-env.sh', mode: '755' }
  when: "'spark_master' in group_names or 'spark_slave' in group_names"


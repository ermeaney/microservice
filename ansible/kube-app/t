val jdbcDF = spark.read.format("jdbc").options( 
  Map(
  "driver" -> "org.apache.phoenix.jdbc.PhoenixDriver",
  "url" -> "jdbc:phoenix:zk-0.zk",
  "dbtable" -> "test")).load()

 val lines = spark.readStream .format("kafka").option("subscribe", "message").option("kafka.bootstrap.servers", "kafka-0.kakka:9092").option("startingOffsets", "latest").load().selectExpr("CAST(value AS STRING)", "CAST(topic as STRING)", "CAST(partition as INTEGER)").as[(String, String, Integer)]


import spark.implicits._
val lines = spark.readStream.
            format("kafka").
            option("subscribe", "message").
            option("kafka.bootstrap.servers", "kafka-0.kafka:9092").
            option("startingOffsets", "latest").
            load().
            selectExpr("CAST(value AS STRING)",
                  "CAST(topic as STRING)",
                  "CAST(partition as INTEGER)").
            as[(String, String, Integer)]
        

lines.map { line => line }

import java.sql.DriverManager
import java.sql.Connection

   val driver = "org.apache.phoenix.jdbc.PhoenixDriver"
   val zk="zk-0.zk"
   Class.forName(driver)
   val connectionString = s"jdbc:phoenix:$zk"
   val connection:Connection = DriverManager.getConnection(connectionString)
   val sql = "upsert into  test (mykey, mycolumn) values(?, ?)"

   val statement = connection.prepareStatement(sql)
   statement.setInt(1,3)
   statement.setString(2,"msg")
   statement.executeUpdate()
   connection.commit() 


##########
val wordCounts = lines.flatMap(_.split(" ")).groupBy("value").count()
val query = wordCounts.writeStream.outputMode("complete").format("console").start()

### https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-sql-structured-streaming.html
##https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala

val dataSet = List((2,"kalu"),(3,"khan"))
sc.parallelize(dataSet)
sc.parallelize(dataSet).saveToPhoenix("test",Seq("mykey","mycolumn"), zkUrl = Some("zk-0.zk:2181"))
